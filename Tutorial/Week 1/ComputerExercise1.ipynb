{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARM Computer Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we compare the RiskMetrics VaR to the (Weighted) Historical Simulation approach. We compare the time patterns of the three VaR measures applied to S&P 500 index returns in the period January 2001 through December 2010. Next, we evaluate the three approaches using backtests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efficient programming of the Weighted Historical Simulation method requires a function that can deliver weighted percentiles from a sample. The code for this has been found on the web, and imported here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_quantile(values, quantiles, sample_weight=None, values_sorted=False, old_style=False):\n",
    "    \"\"\" Source: https://stackoverflow.com/questions/21844024/weighted-percentile-using-numpy\n",
    "    Very close to np.percentile, but supports weights.\n",
    "    NOTE: quantiles should be in [0, 1]!\n",
    "    :param values: np.array with data\n",
    "    :param quantiles: array-like with many quantiles needed\n",
    "    :param sample_weight: array-like of the same length as `array`\n",
    "    :param values_sorted: bool, if True, then will avoid sorting of initial array\n",
    "    :param old_style: if True, will correct output to be consistent with np.percentile.\n",
    "    :return: np.array with computed quantiles.\n",
    "    \"\"\"\n",
    "    values = np.array(values)\n",
    "    quantiles = np.array(quantiles)\n",
    "    if sample_weight is None:\n",
    "        sample_weight = np.ones(len(values))\n",
    "    sample_weight = np.array(sample_weight)\n",
    "    assert np.all(quantiles >= 0) and np.all(quantiles <= 1), 'quantiles should be in [0, 1]'\n",
    "\n",
    "    if not values_sorted:\n",
    "        sorter = np.argsort(values)\n",
    "        values = values[sorter]\n",
    "        sample_weight = sample_weight[sorter]\n",
    "\n",
    "    weighted_quantiles = np.cumsum(sample_weight) - 0.5 * sample_weight\n",
    "    if old_style:\n",
    "        # To be convenient with numpy.percentile\n",
    "        weighted_quantiles -= weighted_quantiles[0]\n",
    "        weighted_quantiles /= weighted_quantiles[-1]\n",
    "    else:\n",
    "        weighted_quantiles /= np.sum(sample_weight)\n",
    "    return np.interp(quantiles, weighted_quantiles, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading, using pandas datareader connected to Yahoo! Finance.\n",
    "Note that after creating the returns series R:\n",
    "* observations 0:250 refer to year 2000, used to start up (W)HS\n",
    "* observations 251:2765 refer to 2001-2010, evaluation sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = dt.datetime(2000, 1, 1)\n",
    "en = dt.datetime(2010, 12, 31)\n",
    "data = web.DataReader('^GSPC', 'yahoo', start=st, end=en)\n",
    "S = data['Adj Close']\n",
    "R = 100 * np.log(1 + S.pct_change().dropna())\n",
    "R.name = 'R'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2000-01-04   -3.909918\n",
       "2000-01-05    0.192034\n",
       "2000-01-06    0.095522\n",
       "2000-01-07    2.672995\n",
       "2000-01-10    1.112782\n",
       "                ...   \n",
       "2010-12-27    0.061251\n",
       "2010-12-28    0.077103\n",
       "2010-12-29    0.100864\n",
       "2010-12-30   -0.150936\n",
       "2010-12-31   -0.019081\n",
       "Name: R, Length: 2766, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the above code does not run properly, replace the previous block by the following, which loads the data from the provided csv file; otherwise, skip this block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (Temp/ipykernel_4748/1310708235.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Jinhyun\\AppData\\Local\\Temp/ipykernel_4748/1310708235.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    path = 'C:\\Users\\Jinhyun\\Documents\\GitHub\\Advanced Risk Management\\Tutorial\\Week 1'    # change path to your working directory\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\Users\\Jinhyun\\Documents\\GitHub\\Advanced Risk Management\\Tutorial\\Week 1'    # change path to your working directory\n",
    "os.chdir(path)\n",
    "dframe = pd.read_csv('SP500.csv', parse_dates=True, index_col='Date')\n",
    "S = dframe['SP500']\n",
    "R = 100 * np.log(1 + S.pct_change().dropna())\n",
    "R.name = 'R'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Calculate the 1%, one-day VaR for S&P 500 index returns for each day in the evaluation period (January 2001 through December 2010), using each of the three methods, and keep the result in three vectors / arrays. To get started, this code below already contains the definition of a weight vector w, based on a historical period m = 250, and a parameter $\\lambda = \\eta = 0.94$ for the WHS and RM methods. Note that WHS and the $\\sigma_{t+1}$ sequence in RM need a start-up sample period, for which we use data from the year 2000 (252 observations).\n",
    "\n",
    "*Note*: an easy way to implement the RM method to construct $\\sigma_t^2$ is to use the `series.ewm()` function from `pandas`. Note that in that function, $\\alpha = 1 - \\lambda$, and also that you need to apply this to the *lagged* squared return (so using the `series.shift()` function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.01\n",
    "labda = 0.94\n",
    "m = 250\n",
    "eta = labda\n",
    "tau = np.arange(m,0,-1)\n",
    "w = eta**tau\n",
    "w /= sum(w)          # Weights are sorted from low to high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Make a figure where each of the three VaR measures are plotted against time. Discuss the similarities and differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Investigate the effect of changing the eta ($\\eta$) parameter in the WHS method: what happens if\n",
    "we give eta a value very close to 1, e.g. 0.999?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Construct the hit sequences $I_{t+1} = \\mathbb{I}( R_{t+1} < -VaR_{t+1}^{0.01})$, for each of the three VaR methods.\n",
    "Next, test unconditional coverage and independence using the methods described in the slides (you may also use Christoffersenâ€™s LR tests for comparison). What do you conclude?\n",
    "\n",
    "(*Note*: $\\mathbb{I}$ is the indicator function, so $\\mathbb{I}(A) = 1$ if $A$ is true, and $0$ otherwise.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
