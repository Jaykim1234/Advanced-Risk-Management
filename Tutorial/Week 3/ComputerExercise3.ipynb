{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we compare risk measurement based on a fitted Student’s $t(d)$ distribution to EVT-based risk measurement. We consider a simulated data-set $\\{x_i\\}_{i=1}^T$ of i.i.d. random variables, drawn from a standardized student’s $t(d)$ distribution with $d = 4.5$. The $x_i$’s may be interpreted as minus the standardized shocks; we will focus on the right tail of the distribution.\n",
    "\n",
    "The code below loads the relevant packages and creates a simulated, sorted Pandas series `x`. The data will be sorted in descending order, so from large to small. We take a large sample $T = 10000$, such that we still have a fairly large number of observations in the tail, i.e., $T_u = 0.05T = 500$.\n",
    "\n",
    "Running the code it repeatedly (with different draws `x`, you can see whether the answers to the questions varies with every time you run it, or remains fairly constant. (A full Monte Carlo simulation exercise would involve extending the code to include a loop over different replications, and a method to asses how well different methods work on average.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "The script below has a simple implementation of the maximum likelihood estimator of the degrees-of-freedom parameter $d$. Extend the script to calculate the simple estimate of $d$ based on the sample kurtosis, see Slide 10 of Week 3. Compare the outcomes; which estimate is closer to the true value of $d = 4.5$ that we have used to simulate the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 10000\n",
    "d = 4.5\n",
    "x = stats.t.rvs(d,size=T)*np.sqrt((d-2)/d)      # generated T obs of standardized t(d) \n",
    "x = np.flipud(np.sort(x))                       # sort in descending order (largest first)\n",
    "x = pd.Series(x,name='x')                       # make into Pandas series\n",
    "\n",
    "params = stats.t.fit(x,d,floc=0)        # ML estimation, fixing mean=0\n",
    "d_ML = params[0]                        # MLE of d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "We know that the t-distribution in this case should fit the data very well, because that is how we have simulated it. Let us check this by making a QQ plot of the data versus the $t(d)$ quantiles, with $d$ equal to the ML estimate `d_ML`. You can do this using the `sm.qqplot` function, see the file `CodeWeek3.py` on Canvas. Alternatively, you could make the QQ plot yourself, by using the array of $p_i$ values provided in the script, together with the `stats.t.ppf` function and `plt.scatter`. Run the program repeatedly; you should see that the majority of observations lie on the diagonal line as expected, but sometimes there are a few extreme observations quite far from this line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Calculate the $VaR_p$ based on the estimated $t$ distribution for $p = 0.02$, $p = 0.01$ and $p = 0.005$ (making use of `stats.t.ppf`). Check how well these measures work for this data set, by calculating the percentage of exceedances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "It has been discussed in the theory exercises of this week that EVT implies that we expect a log-log relationship between `x[0:Tu-1]` and `p[0:Tu-1]`, where `p` is the array of $p_i$ values. Investigate this, using the `plt.loglog` function. The slope should be comparable to $-\\xi = -1/d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Tu = 500                                # take Tu as 0.05*T, so use 5% largest values of x\n",
    "u = x[Tu]                               # threshold for EVT\n",
    "p = (np.arange(1,T+1)-0.5)/T            # vector of p_i values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "Apply the Hill estimator to `x[0:Tu-1]`, and compare the estimate $\\hat{\\xi}$ to $1/d$ and $1/\\hat{d}_{ML}$. Are they close to each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "Recalculate the $VaR_p$ based on the EVT estimate $\\hat{\\xi}$ for $p = 0.02$, $p = 0.01$ and $p = 0.005$, using the formula given on Slide 21. Again, calculate the percentage of exceedances, and compare with the theoretical probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
